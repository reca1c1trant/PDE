# Burgers2D LoRA Finetuning Configuration
# Pure PDE Loss Training (no ground truth supervision)
#
# Training Budget (with default settings):
#   - 90 train samples x 100 clips/sample = 9000 clips/epoch
#   - batch_size=4 -> 2250 steps/epoch
#   - 10 epochs -> ~22500 total steps

# Model
model:
  pretrained_path: "./checkpoints_e2e_medium/best.pt"

  # Must match pretrained model config
  in_channels: 6
  noise_level: 0.0  # Disable noise for finetuning
  use_flash_attention: false
  gradient_checkpointing: true

  # Encoder config (must match pretrained)
  encoder:
    version: "v2"
    channels: [64, 128, 256]
    use_resblock: true

  # Transformer config (must match pretrained)
  transformer:
    hidden_size: 768
    num_hidden_layers: 10
    num_attention_heads: 12
    num_key_value_heads: 4
    intermediate_size: 3072
    hidden_act: "silu"
    max_position_embeddings: 4096
    rms_norm_eps: 1.0e-5
    rope_theta: 500000.0
    attention_dropout: 0.0

  # LoRA config
  lora:
    r: 16
    alpha: 32
    dropout: 0.05
    target_modules:
      - "q_proj"
      - "k_proj"
      - "v_proj"
      - "o_proj"
      - "gate_proj"
      - "up_proj"
      - "down_proj"

# Dataset
dataset:
  path: "./burgers2d_nu0.1_0.15_res128_t1000_n100.h5"
  temporal_length: 16  # Will load 17 frames (16+1)
  train_ratio: 0.9
  seed: 42
  clips_per_sample: 976  # K=100 clips per sample per epoch (方案C)

# Physics parameters
physics:
  dt: 0.001001001  # 1/999, time step from Burgers dataset
  dx: 0.0078125    # 1/128, spatial step

# DataLoader
dataloader:
  batch_size: 8
  num_workers: 4
  pin_memory: true

# Training
training:
  max_epochs: 10  # Epoch-based training with balanced sampling
  warmup_steps: 100
  learning_rate: 1.0e-4
  min_lr: 1.0e-6
  weight_decay: 1.0e-4
  betas: [0.9, 0.999]
  grad_clip: 1.0

  # Loss weights
  lambda_data: 0.0   # Not used (no ground truth)
  lambda_pde: 1.0

  mixed_precision: "bf16"
  gradient_accumulation_steps: 1
  eval_interval: 100  # Validate every 100 steps

# Logging
logging:
  project: "pde-burgers-lora"
  entity: "reca1c1trant-ntu"  # Update with your wandb entity
  save_dir: "./checkpoints_burgers_lora"
  log_interval: 10
